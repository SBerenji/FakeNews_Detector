{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The starting point of this project was based on a tutorial from the DataFlair website, with modifications made to the dataset and model.\n",
    "\n",
    "\n",
    "# importing all the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # used to convert text data into numerical features\n",
    "# used to implement passive-aggressive algorithm, which is a classifier used for binary classification\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier \n",
    "# used for evaluating the performance of the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# using kaggle dataset\n",
    "import kagglehub\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "dataset_path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\")\n",
    "#print(\"Path to dataset files:\", dataset_path)\n",
    "\n",
    "\n",
    "# Replace with the dataset file name\n",
    "fake_news_file = os.path.join(dataset_path, \"Fake.csv\")\n",
    "real_news_file = os.path.join(dataset_path, \"True.csv\")\n",
    "\n",
    "\n",
    "# Reading the dataset into dataframes using the pandas library\n",
    "fake_data = pd.read_csv(fake_news_file)\n",
    "real_data = pd.read_csv(real_news_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Senate backs massive increase in military spen...   \n",
      "1   Anonymous GOP Reps Admit Clinton Will Win, Bl...   \n",
      "2   ‘A Gimmick’: It Just Dawned On Republicans Th...   \n",
      "3  USA's Tillerson and Saudi crown prince discuss...   \n",
      "4  U.S. Senate confirms Acosta to head Labor Depa...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  WASHINGTON (Reuters) - The U.S. Senate passed ...  politicsNews   \n",
      "1  Republicans are already predicting doom and gl...          News   \n",
      "2  While on the campaign trail, reality show star...          News   \n",
      "3  RIYADH (Reuters) - U.S. Secretary of State Rex...     worldnews   \n",
      "4  WASHINGTON (Reuters) - R. Alexander Acosta was...  politicsNews   \n",
      "\n",
      "                  date label  \n",
      "0  September 18, 2017   REAL  \n",
      "1      August 11, 2016  FAKE  \n",
      "2      January 7, 2017  FAKE  \n",
      "3   November 20, 2017   REAL  \n",
      "4      April 27, 2017   REAL  \n",
      "Index(['title', 'text', 'subject', 'date', 'label'], dtype='object')\n",
      "label\n",
      "FAKE    23481\n",
      "REAL    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Adding labels to each dataset\n",
    "fake_data['label'] = 'FAKE'\n",
    "real_data['label'] = 'REAL'\n",
    "\n",
    "# Merging the datasets into a single dataframe\n",
    "df = pd.concat([fake_data, real_data], ignore_index=True)\n",
    "\n",
    "# Shuffling the dataset to ensure randomness\n",
    "df = df.sample(frac=1, random_state=7).reset_index(drop=True)\n",
    "\n",
    "# Checking the structure of the dataset\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# Getting the labels from the dataframe\n",
    "labels = df['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7,  stratify=labels)\n",
    "\n",
    "# df['text'] is the feature set, the model will use this text data to learn patterns (get trained)\n",
    "# labels extracted previously is the target variable (fake or real news) which the model will predict\n",
    "# test size is set to 0.2 which means 20% of the data will be used for testing and 80% will be used for training\n",
    "# the seed (random_state) is set to 7 so we can get the same training and testing sets when using this seed\n",
    "# the funciton returns 4 subsets: \n",
    "# 80% of the text data for training the model (x_train)\n",
    "# 20% of the text data used for testing the model (x_test)\n",
    "# Corresponding labels for the training data (y_train)\n",
    "# Corresponding labels for the testing data (y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialzing the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8,max_features=5000, ngram_range=(1, 2))\n",
    "# Based on stop_words='english, the common english words like 'and' or 'the' will not be considered when trying to distinguish if the news is fake or real\n",
    "# Based on max_df=0.7, words that appear in more than 70% of the documents will be ignored.\n",
    "# (because words with high document frequency (e.g., \"news,\" \"article\") are less informative)\n",
    "# By using ngram_range=(1, 2) the vectorizer considers both unigrams (individual words) and bigrams (two consecutive words) as features\n",
    "\n",
    "# Fit and transform train set and test set\n",
    "# fit_transform function first learns the parameters from the data and then transforms the data into its numerical representation.\n",
    "# The vocabulary (set of unique words) and their corresponding IDF scores are learned from the training data and stored in the vectorizer object.\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "# transform function applies the previously learned parameters (from fit_transform) to new data without re-learning them\n",
    "# Here the vectorizer does not learn anything new. It applies the same vocabulary and IDF values to transform x_test into a numerical matrix.\n",
    "# For words in the test data that are in the vocabulary, their TF-IDF scores are computed using the IDF values from the training data.\n",
    "tfidf_test = tfidf_vectorizer.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 99.42%\n"
     ]
    }
   ],
   "source": [
    "# Initializing a PassiveAggressiveClassifier\n",
    "pac = PassiveAggressiveClassifier(max_iter=50, C=0.1)\n",
    "pac.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predicting on the test set and calculating the accuracy of the model\n",
    "y_pred = pac.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of the model: {round(score*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4674,   22],\n",
       "       [  30, 4254]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing a confusion matrix\n",
    "# The result will show how many of the news were correctly predicted as fake or real\n",
    "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL']) #first row is for the ones labeled as 'fake' and second row is for 'real' label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.99      1.00      0.99      4696\n",
      "        REAL       0.99      0.99      0.99      4284\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['FAKE', 'REAL']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
